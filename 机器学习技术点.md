
# 机器学习技术点


## 标量信号


## 连接主义


## 迁移学习
迁移学习（Transfer Learning,TL）对于人类来说，就是掌握举一反三的学习能力。比如我们学会骑自行车后，学骑摩托车就很简单了；在学会打羽毛球之后，再学打网球也就没那么难了。对于计算机而言，所谓迁移学习，就是能让现有的模型算法稍加调整即可应用于一个新的领域和功能的一项技术。  

传统机器学习通常有两个基本假设，即训练样本与测试样本满足独立同分布的假设和必须有足够可利用的训练样本假设。然而，现实生活中这两个基本假设有时往往难以满足。比如，股票数据的时效性通常很强，利用上个月数据训练出来的模型，往往很难顺利地运用到下个月的预测中去；比如公司开设新业务，但愁于没有足够的数据建立模型进行用户推荐。近年来在机器学习领域受到广泛关注的迁移学习恰恰解决了这两个问题。迁移学习用已有的知识来解决目标领域中仅有少量有标签样本数据甚至没有数据的学习问题，从根本上放宽了传统机器学习的基本假设。由于被赋予了人类特有的举一反三的智慧，迁移学习能够将适用于大数据的模型迁移到小数据上，发现问题的共性，从而将通用的模型迁移到个性化的数据上，实现个性化迁移。  

[独家：一文读懂迁移学习（附学习工具包）](http://www.xtecher.com/Xfeature/view?aid=7383)  


## 强化学习(Reinforcement Learning)
当前的机器学习算法分为三种：监督学习，无监督学习和强化学习。  

强化学习通过不断尝试，获得反馈，然后改进行为，再次尝试，如此循环往复。在尝试和反馈中寻找规律，达到学习的目的，是一种闭环学习方式。  

强化学习是一个算法家族。 根据是否对环境预先建模，是否对尝试进行限制，分为不理解环境和理解环境，不理解环境的算法包括：Q learning，Sarsa，Policy Gradients；理解环境的算法包括：Alpha go。 根据反馈的方式，分为基于概率和基于价值，基于概率的每种行动都有可能被选择，只是概率不同，基于价值的，只有价值最高的行动会被选择，基于概率的算法：Policy Gradients；基于价值的算法：Q learning, Sarsa；两者结合的算法：Actor-Critic。 根据反馈的时机，分为回合更新和单步更新，回合更新包括：Monte-carlo learning，基础版的Policy Gradients；单步更新包括：Q learning, Sarsa，升级版的Policy gradients。 根据是否需要自己亲自玩，分为在线学习和离线学习，在线学习包括：Sarsa，Sarsa lambda，离线学习包括：Q learning，Deep-Q-Network。  


## 凸优化
机器学习中的最优化问题  

