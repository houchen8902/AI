
# 机器学习算法

算法类型

## 监督学习
包括分类和回归  

决策树、集成（装袋、提升、随机森林）、k-NN、线性回归、朴素贝叶斯、神经网络、逻辑回归、感知器、支持向量机(SVM)，相关向量机(RVM)、CART


## 聚类
BIRCH、层次、k平均、期望最大化(EM)、DBSCAN、OPTICS、均值飘移


## 降维
因子分析、CCA、ICA、LDA、NMF、PCA、LASSO、t-SNE


## 结构预测
概率图模型（贝叶斯网络，CRF，HMM）

## 异常检测
k-NN、局部离群因子


## 无监督学习
无监督学习问题可以有三种类型
关联：发现数据集合中的相关数据共现的概率。它广泛用于市场篮子分析。例如：如果顾客购买面包，他有80％的可能购买鸡蛋。
群集：对样本进行分组，使得同一个群集内的对象彼此之间的关系比另一个群集中的对象更为相似。
维度降低：维度降低意味着减少数据集的变量数量，同时确保重要的信息仍然传达。可以使用特征提取方法和特征选择方法来完成维度降低。特征选择选择原始变量的一个子集。特征提取执行从高维空间到低维空间的数据转换。例如：PCA算法是一种特征提取方法。
Apriori，K-means，PCA是无监督学习的例子

## 强化学习
Q学习、SARSA、时间差分学习
强化学习是一种机器学习算法，它允许代理根据当前状态决定最佳的下一个动作
强化算法通常通过反复试验来学习最佳行为。它们通常用于机器人的训练，机器人可以通过在碰到障碍物后接收负面反馈来学习避免碰撞。近期的alphago zero就是采用的强化学习的方法，来完成实验的


## 神经网络
自编码、深度学习、多层感知机、RNN、受限玻尔兹曼机、SOM、CNN


## 理论
偏差/方差困境、计算学习理论、经验风险最小化、PAC学习、统计学习、VC理论


## 回归算法
线性回归
1. 最小二乘法（Ordinary Least Square）
2. 逻辑回归（Logistic Regression）
3. 逐步式回归（Stepwise Regression）
4. 多元自适应回归样条（Multivariate Adaptive Regression Splines）
5. 本地散点平滑估计（Locally Estimated Scatterplot Smoothing）

## 基于实例的算法
1. K最近邻算法(knn)
K邻近算法使用整个数据集作为训练集，而不是将数据集分成训练集和测试集
当新的数据实例需要结果时，KNN算法遍历整个数据集，以找到新实例的k个最近的实例，或者与新记录最相似的k个实例，然后对于分类问题的结果（对于回归问题）或模式输出均值。
实例之间的相似度使用欧几里德距离和Hamming距离等度量来计算。
2. 学习矢量量化
3. 自组织映射算法

## 正则化方法
1. Ridge Regression
2. LASSO
3. 弹性网络

## 决策树学习
1. 分类及回归树（CART）
2. ID3 (Iterative Dichotomiser 3)
3. 决策树C4.5
4. CHAID
5. Desision Stump
6. 随机森林
7. 多元自适应回归样条
8. 梯度推进机
9. 袋装决策树（bagged decision trees）

## 贝叶斯方法
1. 朴素贝叶斯算法
计算事件发生的概率
2. 平均单依赖估计（Averaged One-Dependence Estimators， AODE）
3. Bayesian Belief Network（BBN）

## 基于核的算法
1. 支持向量机
2， 径向基函数
3， 线性判别分析 LDA

## 聚类算法
1， K-means算法
2， 最大期望算法

## 关键规则学习
1， Aprioi算法
2， Eclat算法

## 人工神经网络
1， 感知器神经网络（Perceptron Neural Network
2， 反向传递（Back Propagation）
3， Hopfield网络
4， 自组织映射（Self-Organizing Map, SOM）
5， 学习矢量量化（Learning Vector Quantization， LVQ）

## 深度学习
1， 受限波尔兹曼机
2， Deep Belief Networks（DBN）
3， 卷积网络（Convolutional Network）
4， 堆栈式自动编码器（Stacked Auto-encoders

## 降低维度算法
1， 主成份分析（Principle Component Analysis， PCA）
2， 偏最小二乘回归（Partial Least Square Regression，PLS）
3， Sammon映射
4， 多维尺度（Multi-Dimensional Scaling, MDS）, 
5， 投影追踪（Projection Pursuit）

## 集成算法
1， Boosting
2， Bootstrapped Aggregation（Bagging）
3， AdaBoost
4， 堆叠泛化（Stacked Generalization， Blending）
5， 梯度推进机（Gradient Boosting Machine, GBM）
6， 随机森林（Random Forest）
7. Boosting with AdaBoost


1. 遗传算法
7. PageRank
K均值算法
马尔可夫
奇异值分解（Singular Value Decomposition，SVD）
独立成分分析（Independent Component Analysis，ICA）


## 10大机器学习算法

1. C4.5决策树
2. K-均值(K-means)
3. 支持向量机(SVM)
4. Apriori
5. 最大期望算法（EM）
6. PageRank算法
7. AdaBoost算法
8. k-近邻算法(kNN)
9. 朴素贝叶斯算法(NB)
10. 分类回归树(CART)


### 分类算法（监督学习）
1. k-近邻算法(kNN)
2. C4.5决策树
3. 朴素贝叶斯算法(NB)
4. Logistic回归算法
5. 支持向量机
6. AdaBoost集成方法

### 连续型数值的回归预测（监督学习）
1. 加权线性回归
2. 分类回归树(CART)

### 无监督学习
1. K-均值聚类算法(K-means)
2. 关联分析的Apriori算法
3. FP-Growth算法改进关联分析


## 问题
分类、聚类、回归、异常检测、关联规则、强化学习、结构预测、特征学习、在线学习、半监督学习、语法归纳

